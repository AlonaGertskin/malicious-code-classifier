{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17e4eb8",
   "metadata": {},
   "source": [
    "# Extractor Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e9b77",
   "metadata": {},
   "source": [
    "## Project Setup:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfd9d6",
   "metadata": {},
   "source": [
    "\n",
    "**Decisions Made**:\n",
    "- Chose regex-based approach over ML for initial detection\n",
    "- Decided to focus on Python and C languages first\n",
    "- Created modular structure (extractor/, tests/, classifier/)\n",
    "\n",
    "**Code Changes:**\n",
    "- Created initial patterns.py with simple regex patterns\n",
    "\n",
    "    added patterns that appear in python, C or both in a dictionary\n",
    "\n",
    "- Basic CodeDetector class framework\n",
    "\n",
    "    initialied the class and added a main function detect_code\n",
    "\n",
    "- created basic tests\n",
    "\n",
    "    created simple codes for C and python containing only code - a hello world function for initial testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348ae6d",
   "metadata": {},
   "source": [
    "## Initial Algorithm Architecture - Simple Block Detection\n",
    "\n",
    "Focus: Basic line-by-line scanning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcceeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_code(self, text):\n",
    "    # Simple sequential scanning\n",
    "    lines = text.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if self._is_code_like(lines[i]):\n",
    "            block = self._extract_block(lines, i)\n",
    "            # Process block..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ff69f",
   "metadata": {},
   "source": [
    "### Key Decisions\n",
    "\n",
    "Decision: Line-by-line sequential scanning\n",
    "Rationale: check each line for code patterns, then extract blocks when found\n",
    "\n",
    "### Technical Approach\n",
    "\n",
    "Pattern Detection: _is_code_like() - boolean check against all regex patterns\n",
    "Block Extraction: _extract_block() - placeholder for boundary detection\n",
    "Language ID: Simple pattern counting approach\n",
    "\n",
    "Critical Limitation Discovered\n",
    "Problem: This approach assumes code appears in contiguous blocks, but real-world code can be fragmented with text interspersed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a09c54",
   "metadata": {},
   "source": [
    "## Algorithm Evolution - From Block-Based to Fragment-Based Detection\n",
    "\n",
    "Major Paradigm Shift: Abandoned sequential block extraction for fragment collection + grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW APPROACH:\n",
    "for i, line in enumerate(lines):\n",
    "    scores = self.identify_language_for_line(line)\n",
    "    if max_score >= 0.4:\n",
    "        code_fragments.append({...})\n",
    "return self.group_by_language(code_fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2829d",
   "metadata": {},
   "source": [
    "### Key Innovation\n",
    "\n",
    "Fragment Collection: Each line scored independently\n",
    "Language-Specific Scoring: identify_language_for_line() with weighted patterns\n",
    "Post-Processing Grouping: group_by_language() assembles fragments into blocks\n",
    "\n",
    "### Technical Improvements\n",
    "\n",
    "Weighted Pattern System: Moved from boolean to scored detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42941eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'function_def': (r'def\\s+\\w+\\s*\\(.*\\):', 0.8)  # High weight for strong indicators\n",
    "'comments': (r'#.*$', 0.2)                      # Low weight for weak indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0606682",
   "metadata": {},
   "source": [
    "Threshold-Based Detection: 0.4 threshold prevents noise, can be changed according to testing\n",
    "Language Separation: Groups fragments by detected language before block assembly\n",
    "\n",
    "### Problem Solved\n",
    "Issue: Fragmented code (explanatory text between code lines) wasn't handled properly\n",
    "Solution: Collect all code-like lines first, then intelligently group them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de951",
   "metadata": {},
   "source": [
    "### Status\n",
    "\n",
    "- Core algorithm completely rewritten\n",
    "- Old block-based methods kept as fallback but unused\n",
    "- Foundation for current multi-pass structural analysis\n",
    "\n",
    "#### Next Challenge Identified\n",
    "Need to handle multiline constructs (comments, unmatched braces) that this approach still misses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e168d2",
   "metadata": {},
   "source": [
    "## Two-Pass Architecture Design - Structural Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fbabe",
   "metadata": {},
   "source": [
    "Problem Identified: Missing structural elements break code detection\n",
    "\n",
    "- C closing braces } not recognized as code\n",
    "- Multiline comments /* */ and \"\"\" span detection boundaries\n",
    "- Fragments miss complete constructs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fde5b",
   "metadata": {},
   "source": [
    "Proposed Solution: Two-Pass System\n",
    "Pass 1: Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current fragment-based approach becomes Pass 1\n",
    "scan_for_code_patterns()      # Line-by-line scoring (current logic)\n",
    "identify_structural_elements() # Find braces, quotes, delimiters\n",
    "detect_multiline_starts()     # Function defs, comment starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a772e17",
   "metadata": {},
   "source": [
    "Pass 2: Language-Aware Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40265e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_multiline_constructs() # Match opening/closing pairs\n",
    "find_block_boundaries()        # Use language rules for boundaries\n",
    "validate_block_integrity()     # Ensure structural completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc96e8",
   "metadata": {},
   "source": [
    "### Language-Specific Rules\n",
    "\n",
    "C: Match {} braces, /* */ comments\n",
    "Python: Match \"\"\" docstrings, indentation blocks, \\ continuations\n",
    "\n",
    "### Architecture Benefits\n",
    "\n",
    "Separation of concerns: Pattern detection vs. structural analysis\n",
    "Language-aware completion: Each language has different rules\n",
    "Robust boundary detection: Handles complex multiline constructs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776b5a8",
   "metadata": {},
   "source": [
    "## Structural Analysis Implementation - Pass 2 Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95defb02",
   "metadata": {},
   "source": [
    "Major Addition: analyze_structure() - language-aware structural validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_structure(self, content, language, start_line):\n",
    "    # Track brace balance across entire block\n",
    "    round_brace_counter += line.count('(') - line.count(')')\n",
    "    # Detect multiline comment boundaries\n",
    "    process_multiline_comments(line, language, ...)\n",
    "    # Identify structural imbalances\n",
    "    if braces_sum != 0: # Unmatched braces detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769ea88",
   "metadata": {},
   "source": [
    "### Key Features Implemented\n",
    "\n",
    "Brace Tracking: Cumulative counters for (), [], {} across block\n",
    "Comment Detection: Language-specific multiline comment handling\n",
    "\n",
    "- C: /* */ pairs\n",
    "- Python: \"\"\" pairs\n",
    "\n",
    "Structural Validation: Detect incomplete constructs\n",
    "\n",
    "## Technical Approach\n",
    "\n",
    "Per-line analysis: Track running totals of brace balance\n",
    "State machine: in_comment flag tracks multiline comment state\n",
    "Language dispatch: Different comment delimiters per language\n",
    "\n",
    "### Problem Addressed\n",
    "Missing closing elements (like } in C) now detected as structural imbalances requiring correction.\n",
    "\n",
    "### Current Status\n",
    "\n",
    "Detection logic implemented\n",
    "fix_braces() placeholder for correction logic\n",
    "Foundation for block boundary expansion\n",
    "\n",
    "Next Steps Identified\n",
    "\n",
    "Implement brace correction/expansion\n",
    "Add block merging for adjacent fragments\n",
    "Test with real Stack Overflow data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8a415",
   "metadata": {},
   "source": [
    "## Enhanced Structural Analysis - Error Tracking & Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d5336",
   "metadata": {},
   "source": [
    "Major Improvement: Transformed simple counters into detailed error tracking system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD: Simple counters\n",
    "round_brace_counter += line.count('(') - line.count(')')\n",
    "\n",
    "# NEW: Error tracking with line positions\n",
    "brace_errors = {'round': [], 'square': [], 'curly': []}\n",
    "# Track which lines have unmatched opens\n",
    "if counters[i] > 0 and count > 0:\n",
    "    brace_errors[brace_type].extend([line_index] * count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbbfc4",
   "metadata": {},
   "source": [
    "### Key Innovation\n",
    "Line-level error tracking: Instead of just counting imbalances, now tracking exactly which lines have unmatched opening braces.\n",
    "Smart matching logic:\n",
    "\n",
    "New opens → add line numbers to error list\n",
    "Closes → remove from error list (LIFO matching)\n",
    "Remaining errors = unmatched opens needing correction\n",
    "\n",
    "### Data Structure Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "return {\n",
    "    'multiline_comments': [{'start': X, 'end': Y}],\n",
    "    'brace_errors': {'round': [line_nums], 'curly': [line_nums]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df3b26",
   "metadata": {},
   "source": [
    "### Problem This Solves\n",
    "Now can identify exactly which C functions are missing closing braces and where to look for them in adjacent blocks.\n",
    "Status\n",
    "\n",
    "### Error detection implemented\n",
    "Return structured analysis data\n",
    "Ready for correction logic implementation\n",
    "\n",
    "Next: Use brace_errors to expand blocks and fix structural issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da832fbc",
   "metadata": {},
   "source": [
    "## Complete Structural Recovery Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0577e2b",
   "metadata": {},
   "source": [
    "Major Integration: End-to-end structural analysis with block expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated pipeline\n",
    "for block in code_blocks:\n",
    "    structure_info = self.analyze_structure(...)\n",
    "    block['structure_info'] = structure_info\n",
    "    block = self.expand_blocks_with_comments(block, structure_info, lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651620d4",
   "metadata": {},
   "source": [
    "### Key Features Added\n",
    "1. Enhanced Language Scoring\n",
    "\n",
    "Common patterns now contribute to all languages\n",
    "More accurate language identification per line\n",
    "\n",
    "2. Smart Comment Detection\n",
    "\n",
    "Handles same delimiter cases (Python \"\"\")\n",
    "Detects start/end on same line edge cases\n",
    "Tracks missing comment lines outside block boundaries\n",
    "\n",
    "3. Block Expansion Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b08908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_blocks_with_comments(self, block, structure_info, original_lines):\n",
    "    # Expands block boundaries to include complete multiline comments\n",
    "    all_line_nums.extend(comment_line_ranges)\n",
    "    block['content'] = original_lines[new_start:new_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e1218",
   "metadata": {},
   "source": [
    "### Problem Solved\n",
    "\n",
    "Issue: Multiline comments split across detection boundaries\n",
    "Solution: Post-detection expansion using structural analysis\n",
    "### Technical Innovation\n",
    "\n",
    "Missing line detection: Identifies comment lines outside current block\n",
    "Boundary expansion: Dynamically extends blocks to include complete constructs\n",
    "Content reconstruction: Rebuilds block content from original text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb541f",
   "metadata": {},
   "source": [
    "## Pattern Refinement - Weight Optimization & Edge Case Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3968c",
   "metadata": {},
   "source": [
    "Focus: Fine-tuning detection accuracy through pattern \n",
    "### weights and specialized patterns Pattern Weight Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increased weights for strong indicators\n",
    "'string_literals': 0.2 → better string detection\n",
    "'brackets': 0.2 → improved structural detection\n",
    "'closing_brace': 0.5 → standalone braces now detected\n",
    "\n",
    "# Reduced weights to prevent over-detection\n",
    "'function_call': 0.4 → reduced false positives\n",
    "'parameter_list': 0.2 → more conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c5e32",
   "metadata": {},
   "source": [
    "### New Specialized Patterns Added\n",
    "#### Python-specific:\n",
    "\n",
    "json_structure: \"key\": [{...}] patterns (0.6 weight)\n",
    "multiline_call: Function calls spanning lines\n",
    "list_with_dicts: Complex data structures\n",
    "indented_param: Multi-line function parameters\n",
    "\n",
    "#### C-specific:\n",
    "\n",
    "comment_start/end: Separate /* and */ detection\n",
    "Enhanced preprocessor directives\n",
    "\n",
    "#### Common:\n",
    "\n",
    "closing_brace: Standalone }, ], ) lines\n",
    "object_literal: {key: patterns\n",
    "\n",
    "### Problem Addressed\n",
    "Missing closing braces and complex data structures were being under-detected, causing structural analysis failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98af2f7",
   "metadata": {},
   "source": [
    "## Comprehensive Testing Framework Implementation\n",
    "\n",
    "Focus: Systematic testing infrastructure for algorithm validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_sample_files():\n",
    "    # Automated testing across all sample files\n",
    "    test_files = glob.glob(\"tests/test_samples/*.txt\")\n",
    "    for file_path in test_files:\n",
    "        result, file_result = run_file_test(file_path)\n",
    "        all_results.append(file_result)\n",
    "    save_results_to_file(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798fa14",
   "metadata": {},
   "source": [
    "### Key Features\n",
    "\n",
    "Automated file discovery: Tests all .txt files in samples directory\n",
    "Structured output: Results saved to detection_results.txt with timestamps\n",
    "Error handling: File existence and encoding checks\n",
    "Detailed logging: Block-by-block analysis with confidence scores\n",
    "\n",
    "### Testing Strategy\n",
    "\n",
    "Sample management: Active tests in test_samples/, inactive in more_tests/\n",
    "Pytest integration: python -m pytest tests/test_detector.py -v -s\n",
    "Assertion-based validation: Ensures at least 1 block detected per file\n",
    "\n",
    "Data Collection Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ff208",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"file\": filename,\n",
    "    \"total_blocks\": count,\n",
    "    \"blocks\": [\n",
    "        {\"language\": \"python\", \"confidence\": 1.2, \"content\": [...]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffae76",
   "metadata": {},
   "source": [
    "### Status\n",
    "\n",
    "Testing infrastructure complete\n",
    "Ready for Stack Overflow dataset validation\n",
    "Systematic performance tracking enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacadb8d",
   "metadata": {},
   "source": [
    "## Advanced Cross-Language Correction System\n",
    "\n",
    "Major Feature: reassign_based_on_structure() - intelligent line movement between language blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_based_on_structure(self, blocks):\n",
    "    # Detect C blocks missing closing braces\n",
    "    if block['language'] == 'c' and missing_closes:\n",
    "        # Find Python blocks with standalone closing braces\n",
    "        if first_line in ['}', ']', ')']:\n",
    "            self.move_line_between_blocks(other_block, block, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26a1fd",
   "metadata": {},
   "source": [
    "### Key Innovation\n",
    "\n",
    "Cross-language structural repair: When C code is missing closing braces, algorithm searches other blocks for misclassified closing elements and reassigns them.\n",
    "Enhanced Pattern System\n",
    "\n",
    "Penalty-based scoring: Patterns now penalize competing languages\n",
    "Format: (regex, positive_weight, {penalty_dict})\n",
    "Example: Python def adds 0.8 to Python, subtracts 0.9 from C\n",
    "\n",
    "### Block Expansion Improvements\n",
    "\n",
    "Safe boundary handling: Prevents array bounds errors\n",
    "Set-based line tracking: Efficiently merges comment ranges\n",
    "Content reconstruction: Rebuilds from original text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2213f1",
   "metadata": {},
   "source": [
    "## Orphaned Bracket Recovery + Natural Language Filtering\n",
    "\n",
    "Two Major Additions:\n",
    "1. Orphaned Bracket Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d853d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_orphaned_brackets(self, code_blocks, original_lines):\n",
    "    # Search 3 lines before/after each block for standalone brackets\n",
    "    if line in ['{', '}', ')', ']', '(', '[']:\n",
    "        # Expand block boundaries to include orphaned brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99caee9",
   "metadata": {},
   "source": [
    "2. Natural Language Penalty Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anti-patterns with negative weights\n",
    "'articles': (r'\\b(the|a|an)\\s+\\w+', -0.3, {}),\n",
    "'question_words': (r'\\b(what|how|why)\\b', -0.7, {}),\n",
    "'full_sentences': (r'\\w+\\s+\\w+\\s+\\w+\\s+\\w+\\s+\\w+', -0.2, {}),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c73e1",
   "metadata": {},
   "source": [
    "## Stack Overflow Validation System\n",
    "\n",
    "**Focus**: Real-world testing using actual Stack Overflow questions with embedded code\n",
    "\n",
    "### Key Innovation: Ground Truth Validation\n",
    "\n",
    "```python\n",
    "def stack_overflow_testing():\n",
    "    # Download SO questions, create test files, run validation\n",
    "    get_stackoverflow_data(\"c\", 3)\n",
    "    expected_blocks_dict = create_all_tests(\"c\") \n",
    "    validation_results = validate_detection_results(expected_blocks, detection_results)\n",
    "    save_validation_report(validation_results)\n",
    "```\n",
    "\n",
    "### Major Features Added\n",
    "\n",
    "1. **API Integration**: Downloads real Stack Overflow questions by language tag\n",
    "2. **Ground Truth Extraction**: Extracts expected code from `<pre><code>` HTML tags  \n",
    "3. **Line-by-Line Comparison**: Compares detected vs expected code content\n",
    "4. **Detailed Error Analysis**: Identifies false positives and missed detections with context\n",
    "\n",
    "### Validation Pipeline\n",
    "```python\n",
    "# Extract expected code blocks from Stack Overflow HTML\n",
    "code_blocks = re.findall(r'<pre[^>]*><code[^>]*>(.*?)</code></pre>', html_body, re.DOTALL)\n",
    "\n",
    "# Compare with detection results  \n",
    "for expected_line in expected_lines:\n",
    "    if lines_match(expected_line, detected_line):\n",
    "        correct_matches += 1\n",
    "```\n",
    "\n",
    "### Key Metrics Implemented\n",
    "\n",
    "- **Detection Rate**: Percentage of actual code lines found\n",
    "- **False Positives**: Lines incorrectly detected as code (with percentage)  \n",
    "- **Missed Detections**: Code lines not detected (with percentage)\n",
    "- **File Accuracy**: Percentage of files detected perfectly\n",
    "\n",
    "### Problem Addressed\n",
    "\n",
    "**Issue**: Previous testing used artificial cases that didn't reflect real-world complexity  \n",
    "**Solution**: Stack Overflow questions contain mixed content (code + explanatory text), providing realistic validation data\n",
    "\n",
    "### Status\n",
    "\n",
    "✅ **Complete validation pipeline with real Stack Overflow data**  \n",
    "✅ **Detailed error reporting with line-level context**  \n",
    "✅ **Multi-language testing (Python and C)**  \n",
    "✅ **Quantitative performance metrics**  \n",
    "\n",
    "**Usage**: `python -m tests.test_stack_overflow` generates `stackoverflow_validation.txt`\n",
    "\n",
    "### Impact\n",
    "\n",
    "Enables systematic algorithm improvement through data-driven validation against real-world mixed content instead of artificial test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6689e",
   "metadata": {},
   "source": [
    "## Development Status\n",
    "Code Detection Algorithm - Pattern-Based Implementation\n",
    "Current Phase: Building the core code detection engine using regex patterns and scoring, without AI/ML components.\n",
    "Recent Progress:\n",
    "\n",
    "* Implemented weighted pattern system with language-specific scoring\n",
    "* Fixed brace detection issue - standalone { and } now properly included\n",
    "* Added empty block filtering - eliminates meaningless structural-only blocks\n",
    "* Language-specific pattern penalties - better C vs Python differentiation\n",
    "* Stack Overflow validation pipeline - real-world testing with actual Q&A content\n",
    "\n",
    "Current Performance:\n",
    "\n",
    "83.7% detection rate on recent Stack Overflow questions\n",
    "8.4% false positive rate\n",
    "Works well on pure code, struggles with mixed explanatory content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29610c",
   "metadata": {},
   "source": [
    "# Classifier Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a16bf",
   "metadata": {},
   "source": [
    "## Data Acquisition & Preparation for AI Classification\n",
    "\n",
    "The core challenge for the classification engine was establishing a balanced and labeled ground truth dataset. The existing test files, based primarily on Stack Overflow questions, contained insufficient malicious code for effective deep learning.\n",
    "\n",
    "## Dataset Construction Methodology\n",
    "\n",
    "To mitigate security risks while gathering sufficient samples, all data acquisition was performed within a secured Virtual Machine (VM) environment.\n",
    "\n",
    "## Key Acquisition Decisions:\n",
    "\n",
    "    High-Recall Malicious Code: Raw malware source repositories were cloned, and packed files were extracted (using common passwords like 'infected').\n",
    "\n",
    "    Benign Code Automation: A custom Python script utilizing the GitHub API and a Personal Access Token (PAT) was implemented to bypass rate limits and automatically download large volumes of functional, benign code based on language: and content terms (e.g., searching for import in Python files).\n",
    "\n",
    "    Safety and Standardization: To prepare the input for the ML pipeline and eliminate execution risks, all source code files (.py, .c, .h) were converted to .txt format. This standardizes the input for the next processing phase.\n",
    "\n",
    "## Next Step: Feature Engineering\n",
    "\n",
    "The next critical phase involves converting these raw text files into numerical vectors by extracting behavioral and structural features (e.g., counting sensitive API calls and calculating N-Gram frequency) suitable for the SVM/LSTM classification models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
